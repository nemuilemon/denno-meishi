# 論文読解

『Attention Is All You Need』など、AIに関する重要論文の追試レポートや技術的な考察。

## 記事一覧

- **論文読解レポート：『SINQ: Sinkhorn-Normalized Quantization for LLMs』**
- **論文読解レポート：『REFRAG: Rethinking RAG based Decoding』**
- **論文読解レポート：『Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks』**
- **論文読解レポート：『Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (T5)』**
- **論文読解レポート：『Chain-of-Thought Prompting Elicits Reasoning in Large Language Models』**
- **論文読解レポート：『Attention Is All You Need』**
