# 論文読解レポート：『Chain-of-Thought Prompting Elicits Reasoning in Large Language Models』

## **1. 論文の概要**

本論文は、大規模言語モデル（LLM）の複雑な推論能力を向上させるためのシンプルな手法として**「Chain-of-Thought (CoT) プロンプティング」**を提案し、その有効性を実証した研究である。CoTプロンプティングは、プロンプト内に最終的な回答に至るまでの中間的な思考プロセスを数例含めることで、モデルが自律的に段階的な推論を行い、正答を導き出す能力を向上させる。

この手法は特に算術、常識、記号的推論といったタスクで顕著な性能向上を示し、この推論能力はモデルの規模が特定の閾値を超えた場合にのみ現れる**「創発的な能力（emergent ability）」**であることも明らかにしている。

## **2. Key Idea（本論文の核心的概念）**

本研究の核心は、LLMに対して「最終的な答え」だけでなく**「思考に至るプロセス」**を提示することの重要性を明らかにした点にある。

- **Standard Prompting（標準的プロンプティング）**: 「問題」と「答え」のペアのみを例示する。これはモデルに特定の入出力パターンを学習させることに近い。
    
- **Chain-of-Thought Prompting（CoTプロンプティング）**: 「問題」→「思考のプロセス」→「答え」の3要素をセットで例示する。これにより、モデルは単なる表面的なパターンマッチングから脱却し、問題解決のための**汎用的な論理的プロセス**を学習することが可能となる。この「思考のプロセス」を介在させるという一点が、LLMの応用的な推論能力を飛躍的に向上させるブレークスルーとなった。
    

## **3. 主要な専門用語**

本論文で頻出する主要な専門用語を以下にまとめる。

- **Elicit**: （能力などを）引き出す。CoTプロンプティングが、LLMに内在する推論能力を「引き出す」手法であることを示すために使用される。
    
- **Inter alia**: （ラテン語）とりわけ、など。多数の関連研究を引用する際に、その一部を例として挙げるために用いられる学術的な表現。
    
- **Neuro-symbolic methods**: ニューラルネットワーク（人間の脳神経を模したもの）と、記号論理学を融合させたAIアプローチ。CoTが扱う自然言語による推論とは対照的な、より厳密な形式言語を用いる手法として言及されている。
    
- **Rationale-augmented training**: 答えの根拠（rationale）となる説明文を大量に付与したデータセットでモデルをファインチューニングする手法。高品質なアノテーションを大量に要するため、**annotation costs（注釈コスト）**が非常に高くなる。
    
- **Endow**: （能力などを）授ける。本研究の目的が、LLMにCoTを生成する能力を「授ける」ことであると表現されている。
    
- **Ablation Study（アブレーション研究）**: ある手法の特定の構成要素を意図的に除外（切除）または単純化し、性能の変化を比較することで、その要素の重要性を検証する実験手法。
    
- **Emergent ability（創発的能力）**: モデルの規模が小さい間は観測されないが、特定のスケールを超えると予測不可能な形で現れる能力。CoTによる推論能力の向上は、その典型例とされる。
    
- **Annotator（注釈者）**: CoTプロンプトのお手本となる思考プロセスを記述した人物。本研究では、複数の注釈者が作成したプロンプトでもCoTの有効性が保たれることを示し、その堅牢性を証明した。
    
- **In-domain / Out-of-Domain (OOD)**: モデルが訓練（few-shotの例示）で見た問題と類似の領域（In-domain）と、それよりも複雑または長い未知の領域（OOD）。CoTは特にOODタスクにおける汎化能力（length generalization）を向上させることが示された。
    

## **4. 応用的示唆**

本研究の知見は、LLMとの対話における効果的なプロンプトエンジニアリングの指針となる。

複雑なタスクをモデルに依頼する際、最終的な出力形式だけを指示するのではなく、**タスクを達成するための論理的なステップや中間的な思考プロセスを指示に含める**ことで、モデルの応答の精度と一貫性が大幅に向上することが期待できる。

具体的には、複雑な要求を一度に行うのではなく、「ステップ1としてAを実行し、その結果を用いてステップ2としてBを行い、最終的にCを生成せよ」といったように、思考の連鎖を模倣した指示を与えることが、LLMの潜在能力を最大限に引き出すための有効な戦略であると言える。