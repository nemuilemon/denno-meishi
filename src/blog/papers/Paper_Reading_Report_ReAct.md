# ReAct: Synergizing Reasoning and Acting in Language Models

[https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)

## 1. 論文の概要 (Executive Summary)

### 課題と背景 (Problem)
- **何の課題を解決しようとしているか**: 言語理解や対話型意思決定において、LLMの「推論（Reasoning）」能力と「行動（Acting）」能力が別々に扱われてきたことによる弊害の解決。
- **従来手法の限界**:
    - **Chain-of-Thought (CoT)**: 推論プロセス（思考の連鎖）を生成できるが、外部世界と隔絶された「静的なブラックボックス」であり、事実の幻覚（ハルシネーション）やエラーの連鎖を起こしやすい。
    - **Action-Only**: 行動のみを生成する手法は、高レベルな目標の抽象的な推論や、ワーキングメモリの維持ができず、複雑なタスクで失敗しやすい。

### 提案手法の核心 (Solution)
- **アプローチ (ReAct)**: LLMに対し、「推論トレース（思考）」と「タスク固有の行動」を交互に生成させるパラダイム。
- **仕組み**: 推論（Thought）によって行動計画の作成・維持・修正を行い（Reason to Act）、行動（Action）によって外部ソース（Wikipedia等）から情報を収集し、それを推論に取り込む（Act to Reason）というシナジーを生み出す。

### 主な成果 (Key Results)
- **定量的な成果**:
    - 質問応答（HotpotQA）や事実検証（Fever）において、ハルシネーションを克服し、ベースラインよりも解釈可能な解決プロセスを生成した。
    - 対話型意思決定タスク（ALFWorld, WebShop）において、わずか1〜2ショットのプロンプトで、模倣学習や強化学習の手法を絶対的成功率でそれぞれ34%、10%上回った。
- **定性的な発見**:
    - 「推論」と「行動」を組み合わせることで、モデルの解釈可能性（Interpretability）と信頼性（Trustworthiness）が向上し、人間がプロセスを診断・修正しやすくなった。

## 2. 技術用語と概念の整理 (Technical Glossary)

本論文の理解に不可欠な重要用語を整理する。

- **Reasoning Traces (Thoughts)**:
    - 解説: モデルが行動を起こす前に生成する自然言語による思考プロセス。外部環境には影響を与えず、現在のコンテキストを整理・更新し、将来の行動を支援するために用いられる。

- **Action Space (Augmented)**:
    - 解説: 従来のアクション空間 $\mathcal{A}$ に、言語空間 $\mathcal{L}$ （思考）を加えた拡張アクション空間 $\hat{\mathcal{A}}=\mathcal{A}\cup\mathcal{L}$ を定義する。これにより、思考も一種の「行動」として統一的に扱われる。

- **Chain-of-Thought (CoT)**:
    - 解説: ReActの比較対象となるベースライン。ステップバイステップで推論を行うが、外部情報へのアクセス（行動）を伴わないため、独自の内部知識のみに依存し、事実誤認を起こしやすい。

## 3. 新規性と技術的貢献 (Novelty & Contribution)

- **「推論」と「行動」の相乗効果（Synergy）**:
    - 従来は独立していた「推論（思考）」と「行動（実行）」を密結合させた点。思考が行動を導き（計画）、行動が思考を支える（情報収集）という双方向の補完関係を構築した。

- **一般的かつ柔軟なパラダイム**:
    - 質問応答（QA）のような知識集約型タスクから、Webブラウジングやテキストゲームのような意思決定タスクまで、多様なドメインに適用可能な汎用的なプロンプティング手法を確立した。

- **Human-in-the-loop（人間参加型）への親和性**:
    - 思考プロセスが可視化されるため、人間がモデルの誤った思考を途中で修正（Thought Editing）することで、行動を正しい方向に修正できることが示された。

## 4. アーキテクチャ / 動作原理 (Deep Dive)

ReActは「Thought（思考）」→「Action（行動）」→「Observation（観測）」のループで動作します。

1.  **Thought (思考・推論)**
    - 現在の状況やゴールに基づき、次に何をすべきか、何が必要かを言語化する。
    - 例: 「Apple Remote以外で、このプログラムを制御できるデバイスを探す必要がある」

2.  **Action (行動)**
    - 外部環境に対して具体的なアクションを実行する（検索APIを叩く、Webページをクリックする等）。
    - 例: `Search[Apple Remote]`

3.  **Observation (観測)**
    - 行動の結果（検索結果やAPIのレスポンス）を受け取り、コンテキストに追加する。
    - 例: 「Apple Remoteは...Front Rowメディアセンタープログラムを制御するために設計された...」

- **ループ**:
    - このObservationを受けて、再びステップ1（Thought: 「次はFront Rowを検索する必要があるな」）に戻り、解決するまで繰り返す。

## 5. 考察とプロジェクトへの応用 (Discussion & Application)

### 独自の考察 (Insights)
- **理論的な示唆**:
    - 人間がタスクを行う際の「内部独り言（Inner Speech）」による自己制御プロセスを、LLM上で模倣・再現したものと言える。これは「言語」が単なる通信手段ではなく、認知・推論のためのツールであることを示唆している。

- **限界点**:
    - コンテキスト長への依存度が高く、タスクが複雑になるとプロンプトの長さ制限に抵触する可能性がある。
    - また、ReActはCoTに比べて構造的な制約（思考→行動の繰り返し）があるため、柔軟な推論の定式化においてエラー率が高くなる場合がある。
